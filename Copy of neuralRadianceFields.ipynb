{"cells":[{"cell_type":"markdown","metadata":{"id":"yJzhBu54D49p"},"source":["# Neural Radiance Fields (NERFs)\n","## Kevin Chew Figueroa, David J. Brady\n","## University of Arizona\n","## Spring 2023 \n","## Source:"]},{"cell_type":"markdown","metadata":{"id":"SiiXJ7K_fePG"},"source":["\u003cp align=\"left\"\u003e\n","    \u003cpicture\u003e\n","    \u003csource media=\"(prefers-color-scheme: dark)\" srcset=\"https://docs.nerf.studio/en/latest/_images/logo-dark.png\"\u003e\n","    \u003csource media=\"(prefers-color-scheme: light)\" srcset=\"https://docs.nerf.studio/en/latest/_images/logo.png\"\u003e\n","    \u003cimg alt=\"nerfstudio\" src=\"https://docs.nerf.studio/en/latest/_images/logo.png\" width=\"400\"\u003e\n","    \u003c/picture\u003e\n","\u003c/p\u003e\n","\n","\n","# A collaboration friendly studio for NeRFs\n","\n","\n","![GitHub stars](https://img.shields.io/github/stars/nerfstudio-project/nerfstudio?color=gold\u0026style=social)\n","\n","This colab shows how to train and view NeRFs from Nerfstudio both on pre-made datasets or from your own videos/images.\n","\n","\\\\\n","\n","Credit to [NeX](https://nex-mpi.github.io/) for Google Colab format."]},{"cell_type":"markdown","metadata":{"id":"Yyx5h6kz5ga7"},"source":["## Frequently Asked Questions\n","\n","*  **Downloading custom data is stalling (no output):**\n","    * This is a bug in Colab. The data is processing, but may take a while to complete. You will know processing completed if `data/nerfstudio/custom_data/transforms.json` exists. Terminating the cell early will result in not being able to train.\n","*  **Processing custom data is taking a long time:**\n","    * The time it takes to process data depends on the number of images and its resolution. If processing is taking too long, try lowering the resolution of your custom data.\n","*  **Error: Data processing did not complete:**\n","    * This means that the data processing script did not fully complete. This could be because there were not enough images, or that the images were of low quality. We recommend images with little to no motion blur and lots of visual overlap of the scene to increase the chances of successful processing.\n","*   **Training is not showing progress**:\n","    * The lack of output is a bug in Colab. You can see the training progress from the viewer.\n","* **Viewer Quality is bad / Low resolution**:\n","    * This may be because more GPU is being used on training that rendering the viewer. Try pausing training or decreasing training utilization.\n","* **WARNING: Running pip as the 'root' user...:**:\n","    * This and other pip warnings or errors can be safely ignored.\n","* **Other problems?**\n","    * Feel free to create an issue on our [GitHub repo](https://github.com/nerfstudio-project/nerfstudio).\n"]},{"cell_type":"markdown","metadata":{"id":"LJSgUggTA3p7"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"9oyLHl8QfYwP"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.8.10\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","python3.8 is already the newest version (3.8.10-0ubuntu1~20.04.7).\n","0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n","There are 2 choices for the alternative python3 (providing /usr/bin/python3).\n","\n","  Selection    Path                 Priority   Status\n","------------------------------------------------------------\n","  0            /usr/bin/python3.10   2         auto mode\n","  1            /usr/bin/python3.10   2         manual mode\n","* 2            /usr/bin/python3.8    1         manual mode\n","\n","Press \u003center\u003e to keep the current choice[*], or type selection number: "]}],"source":["#@markdown \u003ch1\u003eInstall Nerfstudio and Dependencies (~8 min)\u003c/h1\u003e\n","#@markdown \n","#@markdown When prompted enter 2 into the prompt, in order to select python3.8\n","!python --version\n","!sudo apt-get install python3.8\n","#change alternatives\n","!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n","!sudo update-alternatives --config python3\n","#check python version\n","!python --version\n","!sudo apt install python3-pip\n","\n","%cd /content/\n","!pip install --upgrade pip\n","!pip install gdown\n","!python --version\n","\n","!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n","#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","\n","# Installing TinyCuda\n","%cd /content/\n","!gdown \"https://drive.google.com/u/1/uc?id=12RL_NVgE9WGvr_fEsXEiuaJ1QESvQCPl\u0026confirm=t\"\n","!pip install tinycudann-1.7-cp38-cp38-linux_x86_64.whl\n","#!gdown \"https://drive.google.com/u/1/uc?id=1LlL2ofrViALsqE789MFGZeJyxkNu84cT\u0026confirm=t\" \n","#!pip install tinycudann-1.7-cp39-cp39-linux_x86_64.whl\n","\n","# Installing COLMAP\n","%cd /content/\n","!gdown \"https://drive.google.com/u/0/uc?id=15WngFRNar_b8CaPR5R-hvQ3eAnlyk_SL\u0026confirm=t\"\n","!sudo apt-get install \\\n","    build-essential \\\n","    libboost-program-options-dev \\\n","    libboost-filesystem-dev \\\n","    libboost-graph-dev \\\n","    libboost-system-dev \\\n","    libboost-test-dev \\\n","    libeigen3-dev \\\n","    libflann-dev \\\n","    libfreeimage-dev \\\n","    libmetis-dev \\\n","    libgoogle-glog-dev \\\n","    libgflags-dev \\\n","    libsqlite3-dev \\\n","    libglew-dev \\\n","    qtbase5-dev \\\n","    libqt5opengl5-dev \\\n","    libcgal-dev \\\n","    libceres-dev\n","!unzip local.zip -d /usr/\n","!chmod +x /usr/local/bin/colmap\n","\n","# Install nerfstudio\n","%cd /content/\n","!pip install git+https://github.com/nerfstudio-project/nerfstudio.git"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":507},"executionInfo":{"elapsed":14888,"status":"error","timestamp":1683856699544,"user":{"displayName":"Gordon Charles","userId":"12161798251733649635"},"user_tz":420},"id":"msVLprI4gRA4","outputId":"f5b06a60-7298-4b1c-aad1-21a511ff221a"},"outputs":[{"data":{"text/html":["\u003ch3\u003eSelect your custom data\u003c/h3\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cp/\u003eYou can select multiple images by pressing ctrl, cmd or shift and click.\u003cp\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cp/\u003eNote: This may take time, especially on hires inputs, so we recommend to download dataset after creation.\u003cp\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["/content/data/nerfstudio/custom_data/raw_images\n"]},{"data":{"text/html":["\n","     \u003cinput type=\"file\" id=\"files-01c6b803-c961-40bf-bb7e-abdcf3c4e753\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" /\u003e\n","     \u003coutput id=\"result-01c6b803-c961-40bf-bb7e-abdcf3c4e753\"\u003e\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      \u003c/output\u003e\n","      \u003cscript\u003e// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) =\u003e {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable\u003c!Object\u003e} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) =\u003e {\n","    inputElement.addEventListener('change', (e) =\u003e {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) =\u003e {\n","    cancel.onclick = () =\u003e {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) =\u003e {\n","      const reader = new FileReader();\n","      reader.onload = (e) =\u003e {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position \u003c fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","\u003c/script\u003e "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-24-85335c15cdfb\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 11\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mkdir -p /content/data/nerfstudio/custom_data/raw_images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/data/nerfstudio/custom_data/raw_images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 44\u001b[0;31m         \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 153\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    154\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    155\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#@markdown \u003ch1\u003e Downloading and Processing Data\u003c/h1\u003e\n","#@markdown \u003ch3\u003ePick the preset scene or upload your own images/video\u003c/h3\u003e\n","import os\n","import glob\n","from google.colab import files\n","from IPython.core.display import display, HTML\n","\n","scene = '\\uD83D\\uDCE4 upload your images' #@param ['ðŸ–¼ poster', 'ðŸšœ dozer', 'ðŸŒ„ desolation', 'ðŸ“¤ upload your images' , 'ðŸŽ¥ upload your own video', 'ðŸ”º upload Polycam data', 'ðŸ’½ upload your own Record3D data']\n","scene = ' '.join(scene.split(' ')[1:])\n","\n","if scene == \"upload Polycam data\":\n","    %cd /content/\n","    !mkdir -p /content/data/nerfstudio/custom_data\n","    %cd /content/data/nerfstudio/custom_data/\n","    uploaded = files.upload()\n","    dir = os.getcwd()\n","    if len(uploaded.keys()) \u003e 1:\n","        print(\"ERROR, upload a single .zip file when processing Polycam data\")\n","    dataset_dir = [os.path.join(dir, f) for f in uploaded.keys()][0]\n","    !ns-process-data polycam --data $dataset_dir --output-dir /content/data/nerfstudio/custom_data/\n","    scene = \"custom_data\"\n","elif scene == 'upload your own Record3D data':\n","    display(HTML('\u003ch3\u003eZip your Record3D folder, and upload.\u003c/h3\u003e'))\n","    display(HTML('\u003ch3\u003eMore information on Record3D can be found \u003ca href=\"https://docs.nerf.studio/en/latest/quickstart/custom_dataset.html#record3d-capture\" target=\"_blank\"\u003ehere\u003c/a\u003e.\u003c/h3\u003e'))\n","    %cd /content/\n","    !mkdir -p /content/data/nerfstudio/custom_data\n","    %cd /content/data/nerfstudio/custom_data/\n","    uploaded = files.upload()\n","    dir = os.getcwd()\n","    preupload_datasets = [os.path.join(dir, f) for f in uploaded.keys()]\n","    record_3d_zipfile = preupload_datasets[0]\n","    !unzip $record_3d_zipfile -d /content/data/nerfstudio/custom_data\n","    custom_data_directory = glob.glob('/content/data/nerfstudio/custom_data/*')[0]\n","    !ns-process-data record3d --data $custom_data_directory --output-dir /content/data/nerfstudio/custom_data/\n","    scene = \"custom_data\"\n","elif scene in ['upload your images', 'upload your own video']:\n","    display(HTML('\u003ch3\u003eSelect your custom data\u003c/h3\u003e'))\n","    display(HTML('\u003cp/\u003eYou can select multiple images by pressing ctrl, cmd or shift and click.\u003cp\u003e'))\n","    display(HTML('\u003cp/\u003eNote: This may take time, especially on hires inputs, so we recommend to download dataset after creation.\u003cp\u003e'))\n","    !mkdir -p /content/data/nerfstudio/custom_data\n","    if scene == 'upload your images':\n","        !mkdir -p /content/data/nerfstudio/custom_data/raw_images\n","        %cd /content/data/nerfstudio/custom_data/raw_images\n","        uploaded = files.upload()\n","        dir = os.getcwd()\n","    else:\n","        %cd /content/data/nerfstudio/custom_data/\n","        uploaded = files.upload()\n","        dir = os.getcwd()\n","    preupload_datasets = [os.path.join(dir, f) for f in uploaded.keys()]\n","    del uploaded\n","    %cd /content/\n","\n","    if scene == 'upload your images':\n","        !ns-process-data images --data /content/data/nerfstudio/custom_data/raw_images --output-dir /content/data/nerfstudio/custom_data/\n","    else:\n","        video_path = preupload_datasets[0]\n","        !ns-process-data video --data $video_path --output-dir /content/data/nerfstudio/custom_data/\n","\n","    scene = \"custom_data\"\n","else:\n","    %cd /content/\n","    !ns-download-data nerfstudio --capture-name=$scene\n","print(scene)\n","print(\"Data Processing Succeeded!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":926},"executionInfo":{"elapsed":5448,"status":"ok","timestamp":1683851533108,"user":{"displayName":"Gordon Charles","userId":"12161798251733649635"},"user_tz":420},"id":"VoKDxqEcjmfC","outputId":"5b11eaec-d3f3-47ed-e460-fc6c6fc9acbe"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n","\u001b[K\u001b[?25h/tools/node/bin/lt -\u003e /tools/node/lib/node_modules/localtunnel/bin/lt.js\n","+ localtunnel@2.0.2\n","updated 1 package in 1.475s\n","https://viewer.nerf.studio/?websocket_url=wss://ripe-clocks-hide.loca.lt\n","You may need to click Refresh Page after you start training!\n"]},{"data":{"text/html":["\n","        \u003ciframe\n","            width=\"100%\"\n","            height=\"800\"\n","            src=\"https://viewer.nerf.studio/?websocket_url=wss://ripe-clocks-hide.loca.lt\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        \u003e\u003c/iframe\u003e\n","        "],"text/plain":["\u003cIPython.lib.display.IFrame at 0x7f9c756ec610\u003e"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["#@markdown \u003ch1\u003eSet up and Start Viewer\u003c/h1\u003e\n","\n","%cd /content\n","\n","# Install localtunnel\n","# We are using localtunnel https://github.com/localtunnel/localtunnel but ngrok could also be used\n","!npm install -g localtunnel\n","\n","# Tunnel port 7007, the default for\n","!rm url.txt 2\u003e /dev/null\n","get_ipython().system_raw('lt --port 7007 \u003e\u003e url.txt 2\u003e\u00261 \u0026')\n","\n","import time\n","time.sleep(3) # the previous command needs time to write to url.txt\n","\n","\n","with open('url.txt') as f:\n","  lines = f.readlines()\n","websocket_url = lines[0].split(\": \")[1].strip().replace(\"https\", \"wss\")\n","# from nerfstudio.utils.io import load_from_json\n","# from pathlib import Path\n","# json_filename = \"nerfstudio/nerfstudio/viewer/app/package.json\"\n","# version = load_from_json(Path(json_filename))[\"version\"]\n","url = f\"https://viewer.nerf.studio/?websocket_url={websocket_url}\"\n","print(url)\n","print(\"You may need to click Refresh Page after you start training!\")\n","from IPython import display\n","display.IFrame(src=url, height=800, width=\"100%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16628,"status":"ok","timestamp":1683853036006,"user":{"displayName":"Gordon Charles","userId":"12161798251733649635"},"user_tz":420},"id":"m_N8_cLfjoXD","outputId":"7ad6e700-19e8-43f7-c049-2da69113b811"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n","\u001b[92mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ \u001b[0mConfig\u001b[92m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n","\u001b[1;35mTrainerConfig\u001b[0m\u001b[1m(\u001b[0m\n","    \u001b[33m_target\u001b[0m=\u001b[1m\u003c\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'nerfstudio.engine.trainer.Trainer'\u001b[0m\u001b[39m\u003e,\u001b[0m\n","\u001b[39m    \u001b[0m\u001b[33moutput_dir\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mPosixPath\u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'outputs'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m    \u001b[0m\u001b[33mmethod_name\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'nerfacto'\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m    \u001b[0m\u001b[33mexperiment_name\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m    \u001b[0m\u001b[33mproject_name\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'nerfstudio-project'\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m    \u001b[0m\u001b[33mtimestamp\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'2023-05-12_005710'\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m    \u001b[0m\u001b[33mmachine\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mMachineConfig\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mseed\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[39m, \u001b[0m\u001b[33mnum_gpus\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m, \u001b[0m\u001b[33mnum_machines\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m, \u001b[0m\u001b[33mmachine_rank\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m, \u001b[0m\u001b[33mdist_url\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'auto'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m    \u001b[0m\u001b[33mlogging\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mLoggingConfig\u001b[0m\u001b[1;39m(\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[33mrelative_log_dir\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mPosixPath\u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'.'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[33msteps_per_log\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[33mmax_buffer_size\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[33mlocal_writer\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mLocalWriterConfig\u001b[0m\u001b[1;39m(\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33m_target\u001b[0m\u001b[39m=\u003cclass \u001b[0m\u001b[32m'nerfstudio.utils.writer.LocalWriter'\u001b[0m\u001b[39m\u003e,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33menable\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mstats_to_track\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m(\u001b[0m\n","\u001b[39m                \u003cEventName.ITER_TRAIN_TIME: \u001b[0m\u001b[32m'Train Iter \u001b[0m\u001b[32m(\u001b[0m\u001b[32mtime\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m\u003e,\u001b[0m\n","\u001b[39m                \u003cEventName.TRAIN_RAYS_PER_SEC: \u001b[0m\u001b[32m'Train Rays / Sec'\u001b[0m\u001b[39m\u003e,\u001b[0m\n","\u001b[39m                \u003cEventName.CURR_TEST_PSNR: \u001b[0m\u001b[32m'Test PSNR'\u001b[0m\u001b[39m\u003e,\u001b[0m\n","\u001b[39m                \u003cEventName.VIS_RAYS_PER_SEC: \u001b[0m\u001b[32m'Vis Rays / Sec'\u001b[0m\u001b[39m\u003e,\u001b[0m\n","\u001b[39m                \u003cEventName.TEST_RAYS_PER_SEC: \u001b[0m\u001b[32m'Test Rays / Sec'\u001b[0m\u001b[39m\u003e,\u001b[0m\n","\u001b[39m                \u003cEventName.ETA: \u001b[0m\u001b[32m'ETA \u001b[0m\u001b[32m(\u001b[0m\u001b[32mtime\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[39m\u003e\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mmax_log_size\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m10\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[33mprofiler\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'basic'\u001b[0m\n","\u001b[39m    \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m    \u001b[0m\u001b[33mviewer\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mViewerConfig\u001b[0m\u001b[1;39m(\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[33mrelative_log_filename\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'viewer_log_filename.txt'\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[33mwebsocket_port\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m7007\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[33mwebsocket_port_default\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m7007\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[33mwebsocket_host\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'0.0.0.0'\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[33mnum_rays_per_chunk\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m32768\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[33mmax_num_display_images\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[33mquit_on_train_completion\u001b[0m\u001b[39m=\u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[33mimage_format\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'jpeg'\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[33mjpeg_quality\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m90\u001b[0m\n","\u001b[39m    \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m    \u001b[0m\u001b[33mpipeline\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mVanillaPipelineConfig\u001b[0m\u001b[1;39m(\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[33m_target\u001b[0m\u001b[39m=\u003cclass \u001b[0m\u001b[32m'nerfstudio.pipelines.base_pipeline.VanillaPipeline'\u001b[0m\u001b[39m\u003e,\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[33mdatamanager\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mVanillaDataManagerConfig\u001b[0m\u001b[1;39m(\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33m_target\u001b[0m\u001b[39m=\u003cclass \u001b[0m\u001b[32m'nerfstudio.data.datamanagers.base_datamanager.VanillaDataManager'\u001b[0m\u001b[39m\u003e,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mdata\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mcamera_optimizer\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mCameraOptimizerConfig\u001b[0m\u001b[1;39m(\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33m_target\u001b[0m\u001b[39m=\u003cclass \u001b[0m\u001b[32m'nerfstudio.cameras.camera_optimizers.CameraOptimizer'\u001b[0m\u001b[39m\u003e,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mmode\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'SO3xR3'\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mposition_noise_std\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33morientation_noise_std\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33moptimizer\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mAdamOptimizerConfig\u001b[0m\u001b[1;39m(\u001b[0m\n","\u001b[39m                    \u001b[0m\u001b[33m_target\u001b[0m\u001b[39m=\u003cclass \u001b[0m\u001b[32m'torch.optim.adam.Adam'\u001b[0m\u001b[39m\u003e,\u001b[0m\n","\u001b[39m                    \u001b[0m\u001b[33mlr\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.0006\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                    \u001b[0m\u001b[33meps\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m1e\u001b[0m\u001b[1;36m-08\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                    \u001b[0m\u001b[33mmax_norm\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                    \u001b[0m\u001b[33mweight_decay\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mscheduler\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mExponentialDecaySchedulerConfig\u001b[0m\u001b[1;39m(\u001b[0m\n","\u001b[39m                    \u001b[0m\u001b[33m_target\u001b[0m\u001b[39m=\u003cclass \u001b[0m\u001b[32m'nerfstudio.engine.schedulers.ExponentialDecayScheduler'\u001b[0m\u001b[39m\u003e,\u001b[0m\n","\u001b[39m                    \u001b[0m\u001b[33mlr_pre_warmup\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m1e\u001b[0m\u001b[1;36m-08\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                    \u001b[0m\u001b[33mlr_final\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m6e\u001b[0m\u001b[1;36m-06\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                    \u001b[0m\u001b[33mwarmup_steps\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                    \u001b[0m\u001b[33mmax_steps\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m200000\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                    \u001b[0m\u001b[33mramp\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'cosine'\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mparam_group\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'camera_opt'\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mdataparser\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mNerfstudioDataParserConfig\u001b[0m\u001b[1;39m(\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33m_target\u001b[0m\u001b[39m=\u003cclass \u001b[0m\u001b[32m'nerfstudio.data.dataparsers.nerfstudio_dataparser.Nerfstudio'\u001b[0m\u001b[39m\u003e,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mdata\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mPosixPath\u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'data/nerfstudio/custom_data'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mscale_factor\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mdownscale_factor\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mscene_scale\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33morientation_method\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'up'\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mcenter_method\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'poses'\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mauto_scale_poses\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mtrain_split_fraction\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.9\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mdepth_unit_scale_factor\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.001\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mtrain_num_rays_per_batch\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m4096\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mtrain_num_images_to_sample_from\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m-1\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mtrain_num_times_to_repeat_images\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m-1\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33meval_num_rays_per_batch\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m4096\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33meval_num_images_to_sample_from\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m-1\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33meval_num_times_to_repeat_images\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m-1\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33meval_image_indices\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mcamera_res_scale_factor\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mpatch_size\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m1\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[33mmodel\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mNerfactoModelConfig\u001b[0m\u001b[1;39m(\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33m_target\u001b[0m\u001b[39m=\u003cclass \u001b[0m\u001b[32m'nerfstudio.models.nerfacto.NerfactoModel'\u001b[0m\u001b[39m\u003e,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33menable_collider\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mcollider_params\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'near_plane'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'far_plane'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m6.0\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mloss_coefficients\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'rgb_loss_coarse'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'rgb_loss_fine'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33meval_num_rays_per_chunk\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m32768\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mnear_plane\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.05\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mfar_plane\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mbackground_color\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'last_sample'\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mhidden_dim\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mhidden_dim_color\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mhidden_dim_transient\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mnum_levels\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mmax_res\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m2048\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mlog2_hashmap_size\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m19\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mnum_proposal_samples_per_ray\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m96\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mnum_nerf_samples_per_ray\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m48\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mproposal_update_every\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mproposal_warmup\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mnum_proposal_iterations\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33muse_same_proposal_network\u001b[0m\u001b[39m=\u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mproposal_net_args_list\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'hidden_dim'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m16\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'log2_hashmap_size'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m17\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'num_levels'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m5\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'max_res'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m128\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'use_linear'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'hidden_dim'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m16\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'log2_hashmap_size'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m17\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'num_levels'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m5\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'max_res'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'use_linear'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[1;39m}\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mproposal_initial_sampler\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'piecewise'\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33minterlevel_loss_mult\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mdistortion_loss_mult\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.002\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33morientation_loss_mult\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.0001\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mpred_normal_loss_mult\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.001\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33muse_proposal_weight_anneal\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33muse_average_appearance_embedding\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mproposal_weights_anneal_slope\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mproposal_weights_anneal_max_num_iters\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33muse_single_jitter\u001b[0m\u001b[39m=\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mpredict_normals\u001b[0m\u001b[39m=\u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[33mdisable_scene_contraction\u001b[0m\u001b[39m=\u001b[0m\u001b[3;91mFalse\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\n","\u001b[39m    \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m    \u001b[0m\u001b[33moptimizers\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[32m'proposal_networks'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m{\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[32m'optimizer'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;35mAdamOptimizerConfig\u001b[0m\u001b[1;39m(\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33m_target\u001b[0m\u001b[39m=\u003cclass \u001b[0m\u001b[32m'torch.optim.adam.Adam'\u001b[0m\u001b[39m\u003e,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mlr\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33meps\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m1e\u001b[0m\u001b[1;36m-15\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mmax_norm\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mweight_decay\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[32m'scheduler'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;35mExponentialDecaySchedulerConfig\u001b[0m\u001b[1;39m(\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33m_target\u001b[0m\u001b[39m=\u003cclass \u001b[0m\u001b[32m'nerfstudio.engine.schedulers.ExponentialDecayScheduler'\u001b[0m\u001b[39m\u003e,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mlr_pre_warmup\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m1e\u001b[0m\u001b[1;36m-08\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mlr_final\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.0001\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mwarmup_steps\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mmax_steps\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m200000\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mramp\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'cosine'\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m        \u001b[0m\u001b[32m'fields'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m{\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[32m'optimizer'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;35mAdamOptimizerConfig\u001b[0m\u001b[1;39m(\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33m_target\u001b[0m\u001b[39m=\u003cclass \u001b[0m\u001b[32m'torch.optim.adam.Adam'\u001b[0m\u001b[39m\u003e,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mlr\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33meps\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m1e\u001b[0m\u001b[1;36m-15\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mmax_norm\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNone\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33mweight_decay\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n","\u001b[39m            \u001b[0m\u001b[32m'scheduler'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;35mExponentialDecaySchedulerConfig\u001b[0m\u001b[1;39m(\u001b[0m\n","\u001b[39m                \u001b[0m\u001b[33m_target\u001b[0m\u001b[39m=\u003cclass \u001b[0m\u001b[32m'nerfstudio.engine.schedulers.ExponentialDecayScheduler'\u001b[0m\u001b[1m\u003e\u001b[0m,\n","                \u001b[33mlr_pre_warmup\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-08\u001b[0m,\n","                \u001b[33mlr_final\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0001\u001b[0m,\n","                \u001b[33mwarmup_steps\u001b[0m=\u001b[1;36m0\u001b[0m,\n","                \u001b[33mmax_steps\u001b[0m=\u001b[1;36m200000\u001b[0m,\n","                \u001b[33mramp\u001b[0m=\u001b[32m'cosine'\u001b[0m\n","            \u001b[1m)\u001b[0m\n","        \u001b[1m}\u001b[0m\n","    \u001b[1m}\u001b[0m,\n","    \u001b[33mvis\u001b[0m=\u001b[32m'viewer'\u001b[0m,\n","    \u001b[33mdata\u001b[0m=\u001b[3;35mNone\u001b[0m,\n","    \u001b[33mrelative_model_dir\u001b[0m=\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'nerfstudio_models'\u001b[0m\u001b[1m)\u001b[0m,\n","    \u001b[33msteps_per_save\u001b[0m=\u001b[1;36m2000\u001b[0m,\n","    \u001b[33msteps_per_eval_batch\u001b[0m=\u001b[1;36m500\u001b[0m,\n","    \u001b[33msteps_per_eval_image\u001b[0m=\u001b[1;36m500\u001b[0m,\n","    \u001b[33msteps_per_eval_all_images\u001b[0m=\u001b[1;36m25000\u001b[0m,\n","    \u001b[33mmax_num_iterations\u001b[0m=\u001b[1;36m30000\u001b[0m,\n","    \u001b[33mmixed_precision\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n","    \u001b[33muse_grad_scaler\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n","    \u001b[33msave_only_latest_checkpoint\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n","    \u001b[33mload_dir\u001b[0m=\u001b[3;35mNone\u001b[0m,\n","    \u001b[33mload_step\u001b[0m=\u001b[3;35mNone\u001b[0m,\n","    \u001b[33mload_config\u001b[0m=\u001b[3;35mNone\u001b[0m,\n","    \u001b[33mload_checkpoint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n","    \u001b[33mlog_gradients\u001b[0m=\u001b[3;91mFalse\u001b[0m\n","\u001b[1m)\u001b[0m\n","\u001b[92mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n","\u001b[2;36m[00:57:11]\u001b[0m\u001b[2;36m \u001b[0mSaving config to: outputs/unnamed/nerfacto/\u001b[1;36m2023\u001b[0m-\u001b[1;36m05\u001b[0m-12_005710/config.yml              \u001b]8;id=3617;file:///usr/local/lib/python3.8/dist-packages/nerfstudio/configs/experiment_config.py\u001b\\\u001b[2mexperiment_config.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=234428;file:///usr/local/lib/python3.8/dist-packages/nerfstudio/configs/experiment_config.py#130\u001b\\\u001b[2m130\u001b[0m\u001b]8;;\u001b\\\n","\u001b[2;36m[00:57:11]\u001b[0m\u001b[2;36m \u001b[0mSaving checkpoints to: outputs/unnamed/nerfacto/\u001b[1;36m2023\u001b[0m-\u001b[1;36m05\u001b[0m-12_005710/nerfstudio_models            \u001b]8;id=234053;file:///usr/local/lib/python3.8/dist-packages/nerfstudio/engine/trainer.py\u001b\\\u001b[2mtrainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=146316;file:///usr/local/lib/python3.8/dist-packages/nerfstudio/engine/trainer.py#140\u001b\\\u001b[2m140\u001b[0m\u001b]8;;\u001b\\\n","\u001b[2;36m[00:57:11]\u001b[0m\u001b[2;36m \u001b[0mSkipping \u001b[1;36m0\u001b[0m files in dataset split train.                                         \u001b]8;id=91161;file:///usr/local/lib/python3.8/dist-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\\u001b[2mnerfstudio_dataparser.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=619176;file:///usr/local/lib/python3.8/dist-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#166\u001b\\\u001b[2m166\u001b[0m\u001b]8;;\u001b\\\n","\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mSkipping \u001b[1;36m0\u001b[0m files in dataset split val.                                           \u001b]8;id=229258;file:///usr/local/lib/python3.8/dist-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\\u001b[2mnerfstudio_dataparser.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=243962;file:///usr/local/lib/python3.8/dist-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#166\u001b\\\u001b[2m166\u001b[0m\u001b]8;;\u001b\\\n","Setting up training dataset\u001b[33m...\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Caching all \u001b[1;36m13\u001b[0m images.\n","\u001b[2KLoading data batch \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:00\u001b[0m\n","\u001b[1A\u001b[2KSetting up evaluation dataset\u001b[33m...\u001b[0m\n","Caching all \u001b[1;36m1\u001b[0m images.\n","\u001b[2KLoading data batch \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:00\u001b[0m\n","\u001b[1A\u001b[2Kâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ \u001b[1;33mViewer\u001b[0m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n","â”‚        â•·                                                                                     â”‚\n","â”‚   HTTP â”‚ \u001b]8;id=225772;https://viewer.nerf.studio/versions/23-05-01-0/?websocket_url=ws://localhost:7007\u001b\\\u001b[34mhttps://viewer.nerf.studio/versions/23-05-01-0/?websocket_url=ws://localhost:7007\u001b[0m\u001b]8;;\u001b\\   â”‚\n","â”‚        â•µ                                                                                     â”‚\n","â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n","\u001b[1m[\u001b[0mNOTE\u001b[1m]\u001b[0m Not running eval iterations since only viewer is enabled.\n","Use \u001b[33m--vis \u001b[0m\u001b[1;33m{\u001b[0m\u001b[33mwandb, tensorboard, viewer+wandb, viewer+tensorboard\u001b[0m\u001b[1;33m}\u001b[0m to run with eval.\n","No Nerfstudio checkpoint to load, so training from scratch.\n","\u001b[1;33mDisabled tensorboard/wandb event writers\u001b[0m\n","\u001b[2;36m[00:57:14]\u001b[0m\u001b[2;36m \u001b[0mPrinting max of \u001b[1;36m10\u001b[0m lines. Set flag \u001b[33m--logging.local-writer.max-log-\u001b[0m\u001b[33msize\u001b[0m\u001b[33m=\u001b[0m\u001b[1;33m0\u001b[0m to disable line        \u001b]8;id=376417;file:///usr/local/lib/python3.8/dist-packages/nerfstudio/utils/writer.py\u001b\\\u001b[2mwriter.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=888662;file:///usr/local/lib/python3.8/dist-packages/nerfstudio/utils/writer.py#405\u001b\\\u001b[2m405\u001b[0m\u001b]8;;\u001b\\\n","\u001b[2;36m           \u001b[0mwrapping.                                                                                       \u001b[2m             \u001b[0m\n","Step (% Done)       Train Iter (time)    ETA (time)           \n","--------------------------------------------------------------\n","Step (% Done)       Train Iter (time)    ETA (time)                                                  \u001b[0m\n","--------------------------------------------------------------                                       \u001b[0m\n","0 (0.00%)           1 s, 133.020 ms      9 h, 26 m, 30 s                                             \u001b[0m\n","---------------------------------------------------------------------------------------------------- \u001b[0m\n","\u001b[6;30;42mViewer at: https://viewer.nerf.studio/versions/23-05-01-0/?websocket_url=ws://localhost:7007         \u001b[0m\n","Traceback \u001b[1m(\u001b[0mmost recent call last\u001b[1m)\u001b[0m:\n","  File \u001b[32m\"/usr/local/lib/python3.8/dist-packages/nerfstudio/scripts/train.py\"\u001b[0m, line \u001b[1;36m186\u001b[0m, in launch\n","    \u001b[1;35mmain_func\u001b[0m\u001b[1m(\u001b[0m\u001b[33mlocal_rank\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mworld_size\u001b[0m=\u001b[35mworld_size\u001b[0m, \u001b[33mconfig\u001b[0m=\u001b[35mconfig\u001b[0m\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/usr/local/lib/python3.8/dist-packages/nerfstudio/scripts/train.py\"\u001b[0m, line \u001b[1;36m101\u001b[0m, in train_loop\n","    \u001b[1;35mtrainer.train\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/usr/local/lib/python3.8/dist-packages/nerfstudio/engine/trainer.py\"\u001b[0m, line \u001b[1;36m244\u001b[0m, in train\n","    loss, loss_dict, metrics_dict = \u001b[1;35mself.train_iteration\u001b[0m\u001b[1m(\u001b[0mstep\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/usr/local/lib/python3.8/dist-packages/nerfstudio/utils/profiler.py\"\u001b[0m, line \u001b[1;36m93\u001b[0m, in inner\n","    out = \u001b[1;35mfunc\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/usr/local/lib/python3.8/dist-packages/nerfstudio/engine/trainer.py\"\u001b[0m, line \u001b[1;36m448\u001b[0m, in train_iteration\n","    _, loss_dict, metrics_dict = \u001b[1;35mself.pipeline.get_train_loss_dict\u001b[0m\u001b[1m(\u001b[0m\u001b[33mstep\u001b[0m=\u001b[35mstep\u001b[0m\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/usr/local/lib/python3.8/dist-packages/nerfstudio/utils/profiler.py\"\u001b[0m, line \u001b[1;36m93\u001b[0m, in inner\n","    out = \u001b[1;35mfunc\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/usr/local/lib/python3.8/dist-packages/nerfstudio/pipelines/base_pipeline.py\"\u001b[0m, line \u001b[1;36m276\u001b[0m, in get_train_loss_dict\n","    ray_bundle, batch = \u001b[1;35mself.datamanager.next_train\u001b[0m\u001b[1m(\u001b[0mstep\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/usr/local/lib/python3.8/dist-packages/nerfstudio/data/datamanagers/base_datamanager.py\"\u001b[0m, line \u001b[1;36m535\u001b[0m, in \n","next_train\n","    ray_bundle = \u001b[1;35mself.train_ray_generator\u001b[0m\u001b[1m(\u001b[0mray_indices\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[1;36m1194\u001b[0m, in _call_impl\n","    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*input, **kwargs\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/usr/local/lib/python3.8/dist-packages/nerfstudio/model_components/ray_generators.py\"\u001b[0m, line \u001b[1;36m54\u001b[0m, in forward\n","    ray_bundle = \u001b[1;35mself.cameras.generate_rays\u001b[0m\u001b[1m(\u001b[0m\n","  File \u001b[32m\"/usr/local/lib/python3.8/dist-packages/nerfstudio/cameras/cameras.py\"\u001b[0m, line \u001b[1;36m453\u001b[0m, in generate_rays\n","    raybundle = \u001b[1;35mcameras._generate_rays_from_coords\u001b[0m\u001b[1m(\u001b[0m\n","  File \u001b[32m\"/usr/local/lib/python3.8/dist-packages/nerfstudio/cameras/cameras.py\"\u001b[0m, line \u001b[1;36m633\u001b[0m, in _generate_rays_from_coords\n","    coord_stack = \u001b[1;35mcamera_utils.radial_and_tangential_undistort\u001b[0m\u001b[1m(\u001b[0m\n","KeyboardInterrupt\n","\n","Printing profiling stats, from longest to shortest duration in seconds\n","Trainer.train_iteration: \u001b[1;36m1.6087\u001b[0m              \n","VanillaPipeline.get_train_loss_dict: \u001b[1;36m1.5826\u001b[0m              \n"]}],"source":["#@markdown \u003ch1\u003eStart Training\u003c/h1\u003e\n","\n","%cd /content\n","if os.path.exists(f\"data/nerfstudio/{scene}/transforms.json\"):\n","    !ns-train nerfacto --viewer.websocket-port 7007 nerfstudio-data --data data/nerfstudio/$scene --downscale-factor 4\n","else:\n","    from IPython.core.display import display, HTML\n","    display(HTML('\u003ch3 style=\"color:red\"\u003eError: Data processing did not complete\u003c/h3\u003e'))\n","    display(HTML('\u003ch3\u003ePlease re-run `Downloading and Processing Data`, or view the FAQ for more info.\u003c/h3\u003e'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33970,"status":"ok","timestamp":1683789076922,"user":{"displayName":"Gordon Charles Hageman","userId":"11516982124644773925"},"user_tz":420},"id":"z2cU9tGBpS3G","outputId":"f05ee246-1b50-4001-b9c3-438d6ae640c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/tyro/_fields.py:794: UserWarning: Mutable type \u003cclass 'nerfstudio.utils.colormaps.ColormapOptions'\u003e is used as a default value for `colormap_options`. This is dangerous! Consider using `dataclasses.field(default_factory=...)` or marking \u003cclass 'nerfstudio.utils.colormaps.ColormapOptions'\u003e as frozen.\n","  warnings.warn(\n","\u001b[2;36m[07:10:48]\u001b[0m\u001b[2;36m \u001b[0mSkipping \u001b[1;36m0\u001b[0m files in dataset split train.                                         \u001b]8;id=586787;file:///usr/local/lib/python3.8/dist-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\\u001b[2mnerfstudio_dataparser.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=600262;file:///usr/local/lib/python3.8/dist-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#166\u001b\\\u001b[2m166\u001b[0m\u001b]8;;\u001b\\\n","\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mSkipping \u001b[1;36m0\u001b[0m files in dataset split test.                                          \u001b]8;id=417025;file:///usr/local/lib/python3.8/dist-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\\u001b[2mnerfstudio_dataparser.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=940665;file:///usr/local/lib/python3.8/dist-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#166\u001b\\\u001b[2m166\u001b[0m\u001b]8;;\u001b\\\n","Loading latest checkpoint from load_dir\n","âœ… Done loading checkpoint from outputs/unnamed/nerfacto/\u001b[1;36m2023\u001b[0m-\u001b[1;36m05\u001b[0m-11_070731/nerfstudio_models/step-\u001b[1;36m000001499.\u001b[0mckpt\n","\u001b[1;32mCreating trajectory video\u001b[0m\n","\u001b[2KðŸŽ¥ Rendering ðŸŽ¥ \u001b[91mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[35m  3%\u001b[0m \u001b[31m0.15 fps\u001b[0m \u001b[36m10:20\u001b[0m\n","\u001b[?25hTraceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/scripts/render.py\", line 134, in _render_trajectory_video\n","    outputs = pipeline.model.get_outputs_for_camera_ray_bundle(camera_ray_bundle)\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/models/base_model.py\", line 178, in get_outputs_for_camera_ray_bundle\n","    outputs = self.forward(ray_bundle=ray_bundle)\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/models/base_model.py\", line 140, in forward\n","    return self.get_outputs(ray_bundle)\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/models/nerfacto.py\", line 265, in get_outputs\n","    ray_samples, weights_list, ray_samples_list = self.proposal_sampler(ray_bundle, density_fns=self.density_fns)\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/model_components/ray_samplers.py\", line 50, in forward\n","    return self.generate_ray_samples(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/model_components/ray_samplers.py\", line 579, in generate_ray_samples\n","    ray_samples = self.initial_sampler(ray_bundle, num_samples=num_samples)\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/model_components/ray_samplers.py\", line 50, in forward\n","    return self.generate_ray_samples(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/model_components/ray_samplers.py\", line 100, in generate_ray_samples\n","    bins = torch.linspace(0.0, 1.0, num_samples + 1).to(ray_bundle.origins.device)[None, ...]  # [1, num_samples+1]\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/ns-render\", line 8, in \u003cmodule\u003e\n","    sys.exit(entrypoint())\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/scripts/render.py\", line 379, in entrypoint\n","    tyro.cli(RenderTrajectory).main()\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/scripts/render.py\", line 362, in main\n","    _render_trajectory_video(\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/scripts/render.py\", line 169, in _render_trajectory_video\n","    writer.add_image(render_image)\n","  File \"/usr/lib/python3.8/contextlib.py\", line 525, in __exit__\n","    raise exc_details[1]\n","  File \"/usr/lib/python3.8/contextlib.py\", line 510, in __exit__\n","    if cb(*exc_details):\n","  File \"/usr/local/lib/python3.8/dist-packages/mediapy/__init__.py\", line 1534, in __exit__\n","    self.close()\n","  File \"/usr/local/lib/python3.8/dist-packages/mediapy/__init__.py\", line 1585, in close\n","    raise RuntimeError(f\"Error writing '{self.path}': {s}\")\n","RuntimeError: Error writing 'renders/2023-05-11_070731/2023-05-11_070731.mp4': \n"]}],"source":["!ns-render --load-config outputs/unnamed/nerfacto/2023-05-11_070731/config.yml --traj filename --camera-path-filename outputs/unnamed/nerfacto/2023-05-11_070731/camera_paths/2023-05-11_070731.json --output-path renders/2023-05-11_070731/2023-05-11_070731.mp4"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"executionInfo":{"elapsed":3311925,"status":"ok","timestamp":1683851305374,"user":{"displayName":"Gordon Charles","userId":"12161798251733649635"},"user_tz":420},"id":"WGt8ukG6Htg3","outputId":"4e101ff1-3776-4af2-8179-a6c60736ac37"},"outputs":[{"data":{"text/html":["\u003ch3\u003eUpload the camera path JSON.\u003c/h3\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["/content/outputs/unnamed/nerfacto/2023-05-11_225356\n"]},{"data":{"text/html":["\n","     \u003cinput type=\"file\" id=\"files-f33f108d-fd88-48a6-a9ae-ba0959e1f647\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" /\u003e\n","     \u003coutput id=\"result-f33f108d-fd88-48a6-a9ae-ba0959e1f647\"\u003e\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      \u003c/output\u003e\n","      \u003cscript\u003e// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) =\u003e {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable\u003c!Object\u003e} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) =\u003e {\n","    inputElement.addEventListener('change', (e) =\u003e {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) =\u003e {\n","    cancel.onclick = () =\u003e {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) =\u003e {\n","      const reader = new FileReader();\n","      reader.onload = (e) =\u003e {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position \u003c fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","\u003c/script\u003e "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving camera_path (1).json to camera_path (1).json\n","/content\n","/usr/local/lib/python3.8/dist-packages/tyro/_fields.py:794: UserWarning: Mutable type \u003cclass 'nerfstudio.utils.colormaps.ColormapOptions'\u003e is used as a default value for `colormap_options`. This is dangerous! Consider using `dataclasses.field(default_factory=...)` or marking \u003cclass 'nerfstudio.utils.colormaps.ColormapOptions'\u003e as frozen.\n","  warnings.warn(\n","\u001b[2;36m[23:33:32]\u001b[0m\u001b[2;36m \u001b[0mSkipping \u001b[1;36m0\u001b[0m files in dataset split train.                                         \u001b]8;id=195799;file:///usr/local/lib/python3.8/dist-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\\u001b[2mnerfstudio_dataparser.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=602704;file:///usr/local/lib/python3.8/dist-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#166\u001b\\\u001b[2m166\u001b[0m\u001b]8;;\u001b\\\n","\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mSkipping \u001b[1;36m0\u001b[0m files in dataset split test.                                          \u001b]8;id=580412;file:///usr/local/lib/python3.8/dist-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\\u001b[2mnerfstudio_dataparser.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=437042;file:///usr/local/lib/python3.8/dist-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#166\u001b\\\u001b[2m166\u001b[0m\u001b]8;;\u001b\\\n","Loading latest checkpoint from load_dir\n","âœ… Done loading checkpoint from outputs/unnamed/nerfacto/\u001b[1;36m2023\u001b[0m-\u001b[1;36m05\u001b[0m-11_225356/nerfstudio_models/step-\u001b[1;36m000001308.\u001b[0mckpt\n","\u001b[1;32mCreating trajectory video\u001b[0m\n","\u001b[2KðŸŽ¥ Rendering ðŸŽ¥ \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[35m 67%\u001b[0m \u001b[31m0.15 fps\u001b[0m \u001b[36m27:21\u001b[0m\n","\u001b[?25hTraceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/scripts/render.py\", line 134, in _render_trajectory_video\n","    outputs = pipeline.model.get_outputs_for_camera_ray_bundle(camera_ray_bundle)\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/models/base_model.py\", line 178, in get_outputs_for_camera_ray_bundle\n","    outputs = self.forward(ray_bundle=ray_bundle)\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/models/base_model.py\", line 140, in forward\n","    return self.get_outputs(ray_bundle)\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/models/nerfacto.py\", line 265, in get_outputs\n","    ray_samples, weights_list, ray_samples_list = self.proposal_sampler(ray_bundle, density_fns=self.density_fns)\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/model_components/ray_samplers.py\", line 50, in forward\n","    return self.generate_ray_samples(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/model_components/ray_samplers.py\", line 579, in generate_ray_samples\n","    ray_samples = self.initial_sampler(ray_bundle, num_samples=num_samples)\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/model_components/ray_samplers.py\", line 50, in forward\n","    return self.generate_ray_samples(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/model_components/ray_samplers.py\", line 100, in generate_ray_samples\n","    bins = torch.linspace(0.0, 1.0, num_samples + 1).to(ray_bundle.origins.device)[None, ...]  # [1, num_samples+1]\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/ns-render\", line 8, in \u003cmodule\u003e\n","    sys.exit(entrypoint())\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/scripts/render.py\", line 379, in entrypoint\n","    tyro.cli(RenderTrajectory).main()\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/scripts/render.py\", line 362, in main\n","    _render_trajectory_video(\n","  File \"/usr/local/lib/python3.8/dist-packages/nerfstudio/scripts/render.py\", line 169, in _render_trajectory_video\n","    writer.add_image(render_image)\n","  File \"/usr/lib/python3.8/contextlib.py\", line 525, in __exit__\n","    raise exc_details[1]\n","  File \"/usr/lib/python3.8/contextlib.py\", line 510, in __exit__\n","    if cb(*exc_details):\n","  File \"/usr/local/lib/python3.8/dist-packages/mediapy/__init__.py\", line 1534, in __exit__\n","    self.close()\n","  File \"/usr/local/lib/python3.8/dist-packages/mediapy/__init__.py\", line 1585, in close\n","    raise RuntimeError(f\"Error writing '{self.path}': {s}\")\n","RuntimeError: Error writing 'renders/output1.mp4': \n","^C\n"]}],"source":["#@title # Render Video { vertical-output: true }\n","#@markdown \u003ch3\u003eExport the camera path from within the viewer, then run this cell.\u003c/h3\u003e\n","#@markdown \u003ch5\u003eThe rendered video should be at renders/output.mp4!\u003c/h5\u003e\n","\n","\n","base_dir = \"/content/outputs/unnamed/nerfacto/\"\n","training_run_dir = base_dir + os.listdir(base_dir)[0]\n","\n","from IPython.core.display import display, HTML\n","display(HTML('\u003ch3\u003eUpload the camera path JSON.\u003c/h3\u003e'))\n","%cd $training_run_dir\n","uploaded = files.upload()\n","uploaded_camera_path_filename = list(uploaded.keys())[0]\n","\n","config_filename = training_run_dir + \"/config.yml\"\n","camera_path_filename = training_run_dir + \"/\" + uploaded_camera_path_filename\n","camera_path_filename = camera_path_filename.replace(\" \", \"\\\\ \").replace(\"(\", \"\\\\(\").replace(\")\", \"\\\\)\")\n","\n","%cd /content/\n","!ns-render --load-config $config_filename --traj filename --camera-path-filename $camera_path_filename --output-path renders/output1.mp4"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","provenance":[{"file_id":"https://github.com/djbradyAtOpticalSciencesArizona/computationalImaging/blob/master/arrayCameras/neuralRadianceFields.ipynb","timestamp":1683770545457}],"version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.13 ('nerfstudio')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.13"},"vscode":{"interpreter":{"hash":"c59f626636933ef1dc834fb3684b382f705301c5306cf8436d2da634c2289783"}}},"nbformat":4,"nbformat_minor":0}